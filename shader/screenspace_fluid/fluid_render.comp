#version 460

#include "../background.glsl"
#include "../brdf.glsl"
#include "../global_bindings.glsl"
#include "../utilities.glsl"

layout(set = 2, binding = 0) uniform texture2D FluidViewSpaceDepth;
layout(set = 2, binding = 1) uniform texture2D WaterDepthTexture;
layout(set = 2, binding = 2) uniform texture2D BackbufferTexture;
layout(set = 2, binding = 3, HDR_BACKBUFFER_IMAGE_FORMAT) uniform restrict image2D BackbufferImage;

layout(local_size_x = 32, local_size_y = 32, local_size_z = 1) in;

const float RefractionIndex_Water = 1.333;
const float RefractionIndex_Air = 1.00029;
const float RefractionAirToWater = RefractionIndex_Water / RefractionIndex_Air; // denoted as Œ∑ (eta)

// from "Acquiring Scattering Properties of Participating Media by Dilution" (https://cseweb.ucsd.edu/~ravir/dilution.pdf)
// Note that I scaled the values back to 1 liter and exctinction per meter.
// The paper lists values for dilutions for which single scattering is accurate - we don't compute multiple scattering so the concentrated liquids
// will not be rendered correctly, especially when the paper lists a low volume!
// ColorExtinctionCoefficient is already "pre-added" with the scattering coefficient since this is the form we need.

// üç∑ Wine (merlot)
// const vec3 HenyeyGreensteinParameterWater = vec3(0.974, 0.0, 0.0);
// const vec3 ColorScatteringCoefficient = vec3(0.0053, 0.0, 0.0) * 10.0 * (23 - 1.5);
// const vec3 ColorExtinctionCoefficient = vec3(0.7639, 1.6429, 1.9196) * 10.0 * (23 - 1.5) + ColorScatteringCoefficient;
// ü•õ Milk (regular) -- doesn't work at all due to missing multiple scattering
// const vec3 HenyeyGreensteinParameterWater = vec3(0.750, 0.714, 0.681);
// const vec3 ColorScatteringCoefficient = vec3(1.1873, 1.3293, 1.4589) * 10.0 * (23 - 0.016);
// const vec3 ColorExtinctionCoefficient = vec3(1.1874, 1.3296, 1.4602) * 10.0 * (23 - 0.016) + ColorScatteringCoefficient;
// Coke
// const vec3 HenyeyGreensteinParameterWater = vec3(0.965, 0.972, 0.0);
// const vec3 ColorScatteringCoefficient = vec3(0.0177, 0.0208, 0.0000) * 10.0 * (23 - 1.6);
// const vec3 ColorExtinctionCoefficient = vec3(0.7143, 1.1688, 1.7169) * 10.0 * (23 - 1.6) + ColorScatteringCoefficient;

// Note that I dropped the *10 factor for the ocean water values - paper says all values are in 10‚àí2mm‚àí1,
// but that doesn't seem to add up for the water measurements, so I assume they are m-1 instead
// Mission Bay Surface Water
// const vec3 HenyeyGreensteinParameterWater = vec3(0.842, 0.865, 0.912);
// const vec3 ColorScatteringCoefficient = vec3(0.2415, 0.2762, 0.3256);
// const vec3 ColorExtinctionCoefficient = vec3(3.3623, 3.2929, 3.2193) + ColorScatteringCoefficient;
// Pacific Ocean Surface Water
// const vec3 HenyeyGreensteinParameterWater = vec3(0.902, 0.825, 0.914);
// const vec3 ColorScatteringCoefficient = vec3(0.1800, 0.1834, 0.2281);
// const vec3 ColorExtinctionCoefficient = vec3(3.3645, 3.3158, 3.2428) + ColorScatteringCoefficient;
// Mission Bay 10ft deep Water 30min
// const vec3 HenyeyGreensteinParameterWater = vec3(0.726, 0.820, 0.921);
// const vec3 ColorScatteringCoefficient = vec3(0.0990, 0.1274, 0.1875);
// const vec3 ColorExtinctionCoefficient = vec3(3.4063, 3.3410, 3.2810) + ColorScatteringCoefficient;
// Mission Bay 10ft deep Water 8hours
// const vec3 HenyeyGreensteinParameterWater = vec3(0.929, 0.910, 0.945);
// const vec3 ColorScatteringCoefficient = vec3(0.1018, 0.1033, 0.1611);
// const vec3 ColorExtinctionCoefficient = vec3(3.3997, 3.3457, 3.2928) + ColorScatteringCoefficient;

// The ocean water measurements look convincing with higher depths, but none of the measured values gets the look I was looking for.
// So here's a synthetic one!
const vec3 HenyeyGreensteinParameterWater = vec3(0.726, 0.820, 0.921);                       // Mission Bay 10ft deep Water 30min
const vec3 ColorScatteringCoefficient = vec3(0.2415, 0.2762, 0.3256);                        // Mission Bay Surface Water
const vec3 ColorExtinctionCoefficient = vec3(0.46, 0.18, 0.06) + ColorScatteringCoefficient; // Made up completely

// Evaluates the refractive part of the rendering equation.
// (Technically also has lambert reflection)
vec3 computeRefraction(float waterDepthAtSeenSurfacePoint, vec3 surfacePosition, vec3 surfaceNormal, vec3 toCamera) {
    // Relevant/good sources on the topic:
    // * https://mtnphil.wordpress.com/2012/09/15/water-shader-follow-up/
    // * PBR Book
    // * "GPU Gems 2, Chapter 13. Volumetric Light Scattering as a Post-Process"
    // (https://developer.nvidia.com/gpugems/gpugems3/part-ii-light-and-shadows/chapter-13-volumetric-light-scattering-post-process)
    // * "Acquiring Scattering Properties of Participating Media by Dilution" (https://cseweb.ucsd.edu/~ravir/dilution.pdf)

    // Estimate refraction.
    // We use waterDepthAtSeenSurfacePoint to estimate where we end up on waterDepth & refraction texture.
    vec3 refractionVector = refract(-toCamera, surfaceNormal, RefractionIndex_Air / RefractionIndex_Water);
    vec3 estimatedRefractionExit = surfacePosition + waterDepthAtSeenSurfacePoint * refractionVector;
    vec3 estimatedRefractionExitProjected = (Camera.ViewProjection * vec4(estimatedRefractionExit, 1.0)).xyw;
    vec2 refractedTexcoord = estimatedRefractionExitProjected.xy / estimatedRefractionExitProjected.z * 0.5 + vec2(0.5);
    refractedTexcoord.y = 1.0 - refractedTexcoord.y;
    ivec2 refractedTexcoordInt = ivec2(Screen.Resolution * refractedTexcoord);
    vec4 refractedBackbuffer = texelFetch(BackbufferTexture, refractedTexcoordInt, 0);
    vec3 refractionRayResult;
    if (refractedBackbuffer.a == 0.0) // The background (or cleared surface) is supposed to write out alpha 0, so we can mask it here.
        // For the background we can compute "perfect" refraction (we only refract on entry, not on exit; so it's still a pretty poor approximiation)
        refractionRayResult = sampleBackground(surfacePosition, refractionVector);
    else
        refractionRayResult = refractedBackbuffer.rgb;
    // sampleBackground(surfacePosition, refractionVector); // imageLoad(BackbufferImage, refractedTexcoordInt).xyz; // TODO. NEED DOUBLE BUFFERING

    // Sampling depth with estimated refraction exit is "too wrong", leads to too many artifacts.
    // But not doing that gives us odd "shadows" in the water thickness, so we take max depth of both to work around the issue a bit.
    float waterDepth =
        max(texelFetch(WaterDepthTexture, ivec2(gl_GlobalInvocationID.xy), 0).x, texelFetch(WaterDepthTexture, refractedTexcoordInt, 0).x) * 3;
    float waterRefractionDepth = waterDepth; // estimate

    // We assume that the "other side" was lit without shadowing from the water mass, light got there unhindered. So we need to fix that first by
    // applying Beer-Lambert law absorption Once we make the water cast shadow, the refractionRayResult will already (more accurately) have this
    // baked-in (waterRefractionDepth is ofc a very simplistic estimate for the distance the light travels through the water)
    refractionRayResult *= exp(-waterRefractionDepth * ColorExtinctionCoefficient);

    // Transmittance/absorption is quite straight forward. Just apply Beer's law.
    // In-scattering is a bit harder to formulate:
    // We want to describe the amount of light that hit the water at some point and was scattered back to us (simpliyfingly assuming single
    // scattering). This can happen along the entire path the light travels and the scattered light itself is subject to absorption.
    // Eventually this amounts to lerping between scattering and refraction ray based on Beer-Lambert law
    vec3 scatteredLight = ColorScatteringCoefficient * DirectionalLightRadiance *
                          evaluateHenyeyGreensteinPhaseFunction(HenyeyGreensteinParameterWater, toCamera, DirectionalLightDirection);

    return mix(scatteredLight, refractionRayResult, exp(-waterRefractionDepth * ColorExtinctionCoefficient));
}

// Evaluates the reflective part of the rendering equation.
vec3 computeReflection(vec3 worldPos, vec3 normal, vec3 toCamera) {

    vec3 reflected = reflect(-toCamera, normal);
    return sampleBackground(worldPos, reflected);
}

void reconstructNormalAndPositionFromDepthbuffer(ivec2 screenCoord, vec2 screenPixelSize, out vec3 worldNormal, out vec3 worldPosition) {
    // Reconstruct normals as describe here:
    // https://wickedengine.net/2019/09/22/improved-normal-reconstruction-from-depth/
    // (Improved normal reconstruction from depth, Turanszkij, September 2019)
    // Btw. here is an even more thorough and expensive one: https://atyuwen.github.io/posts/normal-reconstruction/#fn:2

    ivec2 coordUp = screenCoord + ivec2(0, 1);
    ivec2 coordDown = screenCoord + ivec2(0, -1);
    ivec2 coordRight = screenCoord + ivec2(1, 0);
    ivec2 coordLeft = screenCoord + ivec2(-1, 0);

    // TODO: Shared memory for fetching depth.
    float depthCenter = texelFetch(FluidViewSpaceDepth, screenCoord, 0).r;
    worldPosition = reconstructWorldPositionFromViewSpaceDepth(screenCoord * screenPixelSize, depthCenter);
    float depthUp = texelFetch(FluidViewSpaceDepth, coordUp, 0).r;
    float depthRight = texelFetch(FluidViewSpaceDepth, coordRight, 0).r;
    float depthDown = texelFetch(FluidViewSpaceDepth, coordDown, 0).r;
    float depthLeft = texelFetch(FluidViewSpaceDepth, coordLeft, 0).r;

    uint bestDepthHorizontal = abs(depthRight - depthCenter) < abs(depthLeft - depthCenter) ? 1 : 2;
    uint bestDepthVertical = abs(depthDown - depthCenter) < abs(depthUp - depthCenter) ? 3 : 4;

    // TODO: Simplify
    vec3 p1;
    vec3 p2;
    if (bestDepthHorizontal == 1 && bestDepthVertical == 4) {
        p1 = reconstructWorldPositionFromViewSpaceDepth(coordRight * screenPixelSize, depthRight);
        p2 = reconstructWorldPositionFromViewSpaceDepth(coordUp * screenPixelSize, depthUp);
    } else if (bestDepthHorizontal == 1 && bestDepthVertical == 3) {
        p1 = reconstructWorldPositionFromViewSpaceDepth(coordDown * screenPixelSize, depthDown);
        p2 = reconstructWorldPositionFromViewSpaceDepth(coordRight * screenPixelSize, depthRight);
    } else if (bestDepthHorizontal == 2 && bestDepthVertical == 4) {
        p1 = reconstructWorldPositionFromViewSpaceDepth(coordUp * screenPixelSize, depthUp);
        p2 = reconstructWorldPositionFromViewSpaceDepth(coordLeft * screenPixelSize, depthLeft);
    } else { // if (bestDepthHorizontal == 2 && bestDepthVertical == 3)
        p1 = reconstructWorldPositionFromViewSpaceDepth(coordLeft * screenPixelSize, depthLeft);
        p2 = reconstructWorldPositionFromViewSpaceDepth(coordDown * screenPixelSize, depthDown);
    }

    // Classic version
    // p1 = reconstructWorldPositionFromViewSpaceDepth(coordRight * screenPixelSize, depthRight);
    // p2 = reconstructWorldPositionFromViewSpaceDepth(coordUp * screenPixelSize, depthUp);

    worldNormal = normalize(cross(p2 - worldPosition, p1 - worldPosition));
}

void main() {
    ivec2 screenCoord = ivec2(gl_GlobalInvocationID.xy);
    float waterDepthAtSeenSurfacePoint = texelFetch(WaterDepthTexture, screenCoord, 0).r;
    if (waterDepthAtSeenSurfacePoint == 0.0)
        return;

    vec2 screenPixelSize = vec2(1.0) / textureSize(FluidViewSpaceDepth, 0).xy;

    // Normal/Position (world coords)
    vec3 normal;
    vec3 position;
    reconstructNormalAndPositionFromDepthbuffer(screenCoord, screenPixelSize, normal, position);

    vec3 toCamera = normalize(Camera.Position - position);

    // Color components.
    vec3 refractionColor = computeRefraction(waterDepthAtSeenSurfacePoint, position, normal, toCamera);
    vec3 reflectionColor = computeReflection(position, normal, toCamera);

    // Combine Refraction & Reflection & Specular
    float nDotV = dot(normal, toCamera);
    float fresnel = fresnelDielectricDielectric(nDotV, RefractionAirToWater);
    vec3 color = mix(refractionColor, reflectionColor, fresnel);

    imageStore(BackbufferImage, screenCoord, vec4(color, 1.0));
}