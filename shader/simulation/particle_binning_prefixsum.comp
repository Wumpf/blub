#version 460

// Do a prefix sum over the particle counters (ParticleBinningVolume)
// By doing this we're determining new particle bins!

// TODO: For starters we implement the simplest possible algorithm. Not work optimal.

#include "../global_bindings.glsl"
#include "particle_binning.glsl"

#define LOCAL_SIZE_SCAN 1024

layout(local_size_x = LOCAL_SIZE_SCAN, local_size_y = 1, local_size_z = 1) in;

shared uint sharedBuffer[LOCAL_SIZE_SCAN];

ivec3 IndexToImageAddress(uint index) {
    // Tried a few patterns. X to y to came out fastest as expected. Knowing the tiling/swizzling pattern of the volume we could sure improve even
    // Current guess for my nvidia card/driver is block tiling in xy sliced in z. ðŸ¤”
    // more! Linear x to y to z (fastest!)
    return ivec3(index, index / Rendering.FluidGridResolution.x, index / Rendering.FluidGridResolution.x / Rendering.FluidGridResolution.y) %
           ivec3(Rendering.FluidGridResolution.xyz);
    // Linear y to x to z
    // return ivec3(index / Rendering.FluidGridResolution.y, index, index / Rendering.FluidGridResolution.x / Rendering.FluidGridResolution.y) %
    //       ivec3(Rendering.FluidGridResolution.xyz);
    // Linear z to x to y
    // return ivec3(index / Rendering.FluidGridResolution.z, index / Rendering.FluidGridResolution.x / Rendering.FluidGridResolution.z, index) %
    //       ivec3(Rendering.FluidGridResolution.xyz);
}

void main() {
    uint localIndex = gl_LocalInvocationID.x;
    ivec3 imageAddress = IndexToImageAddress(gl_GlobalInvocationID.x);

    uint result = imageLoad(ParticleBinningVolume, imageAddress).x;

    uint offset = 1;
    while (offset < LOCAL_SIZE_SCAN) {
        sharedBuffer[localIndex] = result;
        barrier();
        if (localIndex >= offset) {
            result += sharedBuffer[localIndex - offset];
        }
        barrier();
        offset *= 2;
    }

    // observation: How much do we care about where particle end up as long as they ar binned?
    // If we don't, then we can do a reduce per block like this:
    // 1024 threads reducing 1024*32 (think 32 cube block (TODO)) and then do atomic adds on a global (for 512 cube block that's still only 4096, for
    // a 256 cube block only 512!). That way we'd save the more complicated and long winded multi pass setup which requires a lot more reads & writes.

    if (localIndex == LOCAL_SIZE_SCAN - 1)
        sharedBuffer[0] = atomicAdd(ParticleBinningAtomicCounter, result);
    barrier();
    result += sharedBuffer[0];

    // Skip write if we're 0. No particle here anyways!
    if (result != 0)
        imageStore(ParticleBinningVolume, imageAddress, uvec4(result));
}
